---
- name: Configure Master Node
  hosts: master_vm_0
  become: yes
  tasks:
    - name: Wait for apt lock to be released
      shell: |
        while fuser /var/lib/dpkg/lock-frontend >/dev/null 2>&1; do
          echo "Waiting for apt lock to be released..."
          sleep 5
        done

    - name: Update apt package index
      apt:
        update_cache: yes

    - name: Create directory for installation
      file:
        path: /home/ubuntu/install
        state: directory
        mode: '0755'

    - name: Install OpenJDK
    #   apt:
    #     name: openjdk-8-jdk
    #     state: present
      copy: 
        src: /home/lousteau/hagimont_software/jdk-8u202-linux-x64.tar.gz
      # get_url:
        # url: https://sd-160040.dedibox.fr/hagimont/software/jdk-8u202-linux-x64.tar.gz
        dest: /home/ubuntu/install/jdk-8u202-linux-x64.tar.gz
        mode: '0644'

    - name: Extract JDK 
      ansible.builtin.unarchive:
        src: /home/ubuntu/install/jdk-8u202-linux-x64.tar.gz
        dest: /home/ubuntu/install
        remote_src: yes

    - name: Set up SSH key for passwordless access
      shell: |
        if [ ! -f /home/ubuntu/.ssh/id_rsa ]; then
          ssh-keygen -t rsa -b 2048 -f /home/ubuntu/.ssh/id_rsa -N ""
        fi

    - name: Copy public key to authorized_keys
      copy:
        src: /home/ubuntu/.ssh/id_rsa.pub
        dest: /home/ubuntu/.ssh/authorized_keys
        owner: ubuntu
        group: ubuntu
        mode: '0644'
        remote_src: yes

    - name: Set permissions for .ssh directory
      file:
        path: /home/ubuntu/.ssh
        state: directory
        mode: '0700'

    - name: Install Spark
      copy: 
        src: /home/lousteau/hagimont_software/jdk-8u202-linux-x64.tar.gz
      # get_url:
        # url: https://sd-160040.dedibox.fr/hagimont/software/spark-2.4.3-bin-hadoop2.7.tgz
        dest: /home/ubuntu/install/spark-2.4.3-bin-hadoop2.7.tgz
        mode: '0644'

    - name: Extract Spark
      ansible.builtin.unarchive:
        src: /home/ubuntu/install/spark-2.4.3-bin-hadoop2.7.tgz
        dest: /home/ubuntu/install
        remote_src: yes

    - name: Set Spark environment variables
      blockinfile:
        path: /home/ubuntu/.bashrc
        block: |
          export SPARK_HOME=/home/ubuntu/install/spark-2.4.3-bin-hadoop2.7
          export PATH=$PATH:$SPARK_HOME/bin:$SPARK_HOME/sbin

    - name: Reload .bashrc
      shell: . /home/ubuntu/.bashrc

    - name: Install Hadoop
      copy: 
        src: /home/lousteau/hagimont_software/hadoop-2.7.1.tar.gz
      # get_url:
        # url: https://sd-160040.dedibox.fr/hagimont_software/software/hadoop-2.7.1.tar.gz
        dest: /home/ubuntu/install/hadoop-2.7.1.tar.gz
        mode: '0644'

    - name: Extract Hadoop
      ansible.builtin.unarchive:
        src: /home/ubuntu/install/hadoop-2.7.1.tar.gz
        dest: /home/ubuntu/install
        remote_src: yes

    - name: Set Hadoop environment variables
      blockinfile:
        path: /home/ubuntu/.bashrc
        block: |
          export HADOOP_HOME=/home/ubuntu/install/hadoop-2.7.1
          export PATH=$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$PATH

    - name: Configure Hadoop core-site.xml
      copy:
        content: |
          <configuration>
            <property>
              <name>fs.defaultFS</name>
              <value>hdfs://master:9000</value>
            </property>
          </configuration>
        dest: /home/ubuntu/install/hadoop-2.7.1/etc/hadoop/core-site.xml

    - name: Configure Hadoop hdfs-site.xml
      copy:
        content: |
          <configuration>
            <property>
              <name>dfs.replication</name>
              <value>2</value>
            </property>
          </configuration>
        dest: /home/ubuntu/install/hadoop-2.7.1/etc/hadoop/hdfs-site.xml

    # - name: Format Hadoop namenode
    #   shell: hdfs namenode -format
    #   args:
    #     executable: /bin/bash
    #   ignore_errors: yes
